---
layout: default
title: Keynotes
rank: 1
---

# üé§ Keynotes

## Invited Talk 1: Cordelia Moore
**Title:** *Gender-based Violence in the Age of AI - Centring Survivor's Needs and Preventing Harm*  
**Speaker:** Cordelia Moore  
**Abstract:**  
With AI tools being more readily available, the many ways technology is fueling the global crisis of gender-based violence becomes apparent. Generative AI is being used with the intent to harm: to exert coercive control and create sexualised deepfake images. Women and girls are disproportionately affected by this and are feeling the impact technology has on the global backlash on their rights and freedom. Survivor support services face a multitude of challenges in addressing these concerns. At the same time, different ethical usages of AI tools are being explored to evaluate their usefulness in supporting survivors. How can we move beyond technology that exaberates existing inequalities and work towards technological justice that centres the needs of survivors and prevents further harm?

**‚ö†Ô∏è Trigger Warning:** gender-based violence, domestic and sexual abuse, stalking, non-consensual image sharing.

---

## Invited Talk 2: Francesco Barbieri *(Meta)*
**Title:** *Closing the Gap: Online Safety in Research and Practice*  
**Speaker:** Francesco Barbieri  
**Abstract:**  
I will be talking about the gap between research and real-world impact in online safety. I will explore why traditional evaluation methods often fail to capture the true cost of safety mispredictions and how we can rethink them to reflect real consequences (whether it‚Äôs missing high-risk content or over-blocking users). 
I will also discuss the challenges of building robust safety systems that can handle shifting domains, changing guidelines, and unexpected failures. 
Finally, I will talk about emerging safety risks in large language models and how techniques like distillation, explainability, and post-training adjustments are shaping safer systems.  The goal of this talk is to highlight why solving online safety requires end-to-end thinking, beyond just improving individual safety classifiers.

---

## Invited Talk 3: Kate Sim *(COSPR)*
**Title:** *The Seduction of Detection: CSAM, Automation, and the Politics of Detection*  
**Speaker:** Kate Sim  
**Abstract:**  
The detection of child sexual abuse materials, or CSAM, occupies a central place in the history and landscape of commercial content moderation. CSAM viscerally conjures up images of innocent children locked in cages and beckons us to assume the role of a detective. Hash matching and classifiers become our magnifying glasses, like forensic tools that capture undeniable proofs of human malice. The allure of detection is seductive. The seductiveness stems from its many promises: the promise of evidentiary certainty; the promise of justice; and the promise of doing good. But what exactly is being detected? What happens after detection? Who or what is the detection in service of? By interrogating the sociotechnical promises embedded in the expanding apparatus of CSAM detection, this talk examines what happens when we reconfigure abuse as a piece of content and develop a global ecosystem preoccupied with searching within the four corners of an image. 

**‚ö†Ô∏è Trigger Warning:** child sexual abuse.

---
