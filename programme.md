---
layout: default
title: Detailed Schedule
rank: 4
---

## <span style="color:#267CB9"> Schedule </span>

Thursday, July 13th 2023. Toronto time. All sessions are in **PIER 7&8** unless indicated otherwise.

09:00 - 09:15:  Opening Remarks

09:15 - 09:45:  **Dirk Hovy**: "Whose Truth Is It Anyway?"

09:45 - 10:15:  **Vinodkumar Prabhakaran**:

10:15 - 11:45:  **Poster Session** in the **Frontenac Ballroom** 

- *Identity Construction in a Misogynist Incels Forum*<br>
Michael Yoder, Chloe Perry, David Brown, Kathleen Carley and Meredith Pruden

- *DeTexD: A Benchmark Dataset for Delicate Text Detection*<br>
Artem Chernodub, Serhii Yavnyi, Oleksii Sliusarenko, Jade Razzaghi, Yichen Mo and Knar Hovakimyan

- *Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech*<br>
Flor Miriam Plaza-del-Arco, Debora Nozza and Dirk Hovy

- *Benchmarking Offensive and Abusive Language in Dutch Tweets*<br>
Tommaso Caselli and Hylke Van Der Veen

- *Concept-Based Explanations to Test for False Causal Relationships Learned by Abusive Language Classifiers*<br>
Isar Nejadgholi, Svetlana Kiritchenko, Kathleen C. Fraser and Esma Balkir

- *Conversation Derailment Forecasting with Graph Convolutional Networks*<br>
Enas Altarawneh, Ameeta Agrawal, Michael Jenkin and Manos Papagelis

- *Resources for Automated Identification of Online Gender-Based Violence: A Systematic Review*<br>
Gavin Abercrombie, Aiqi Jiang, Poppy Gerrard-abbott, Ioannis Konstas and Verena Rieser

- *Disentangling Disagreements on Offensiveness: A Cross-Cultural Study*<br>
Aida Mostafazadeh Davani, Mark Diaz, Dylan Baker and Vinodkumar Prabhakaran

- *Evaluating the Effectiveness of Natural Language Inference for Hate Speech Detection in Languages with Limited Labeled Data*<br>
Janis Goldzycher, Moritz Preisig, Chantal Amrhein and Gerold Schneider

- *Factoring Hate Speech: A New Annotation Framework to Study Hate Speech in Social Media*<br>
Gal Ron, Effi Levi, Odelia Oshri and Shaul Shenhav

- *Toward Disambiguating the Definitions of Abusive, Offensive, Toxic, and Uncivil Comments*<br>
Pia Pachinger, Julia Neidhardt, Allan Hanbury and Anna Maria Planitzer

- *Harmful Language Datasets: An Assessment of Robustness*<br>
Katerina Korre, John Pavlopoulos, Jeffrey Sorensen, Léo Laugier, Ion Androutsopoulos, Lucas Dixon and Alberto Barrón-cede ̃no

- *Robust Hate Speech Detection in Social Media: A Cross-Dataset Empirical Evaluation*<br>
Dimosthenis Antypas and Jose Camacho-Collados

- *[Findings] Responsibility Perspective Transfer for Italian Femicide News*<br>
Gosse Minnema, Huiyuan Lai, Benedetta Muscato and Malvina Nissim

- *[Findings] Scientific Fact-Checking: A Survey of Resources and Approaches*<br>
Juraj Vladika and Florian Matthes

- *[Findings] A New Task and Dataset on Detecting Attacks on Human Rights Defenders*<br>
Shihao Ran, Di Lu, Aoife Cahill, Joel Tetreault and Alejandro Jaimes

- *[Findings] ClaimDiff: Comparing and Contrasting Claims on Contentious Issues*<br>
Miyoung Ko, Ingyu Seong, Hwaran Lee, Joonsuk Park, Minsuk Chang and Minjoon Seo

- *[Findings] Which Examples Should be Multiply Annotated? Active Learning When Annotators May Disagree*<br>
Connor T Baumler, Anna Sotnikova and Hal Daumé III

- *[Findings] Disagreement Matters: Preserving Label Diversity by Jointly Modeling Item and Annotator Label Distributions with DisCo*<br>
Tharindu Cyril Weerasooriya, Alexander Ororbia, Raj B Bhensadadia, Ashiqur KhudaBukhsh and Christopher Homan

- *[Findings] Debiasing should be Good and Bad*<br>
Robert A. Morabito, Jad Kabbara and Ali Emami

- *[Findings] COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements*<br>
Xuhui Zhou, Hao Zhu, Akhila Yerukola, Thomas Davidson, Jena D. Hwang, Swabha Swayamdipta and Maarten Sap

- *[Findings] Stereotypes and Smut: The (Mis)representation of Non-cisgender Identities by Text-to-Image Models*<br>
Eddie L. Ungless, Bjorn Ross and Anne Lauscher


11:45 - 12:15:  **Maarten Sap**: "The Pivotal Role of Social Context in Toxic Language Detection"

12:15 - 13:30:  Lunch Break

13:30 - 14:00:  **Su Lin Blodgett**:

14:00 - 14:30:  **Outstanding Paper Talks**

- *Cross-Platform and Cross-Domain Abusive Language Detection with Supervised Contrastive Learning*<br>
Md Tawkat Islam Khondaker, Muhammad Abdul-mageed and Laks Lakshmanan, V.s.

- *Aporophobia: An Overlooked Type of Toxic Language Targeting the Poor*<br>
Svetlana Kiritchenko, Georgina Curto Rex, Isar Nejadgholi and Kathleen C Fraser


14:30 - 15:00:  **Lightning Talks** for remote attendants

- *Towards Safer Communities: Detecting Aggression and Offensive Language in Code-Mixed Tweets to Combat Cyberbullying*<br>
Nazia Nafis, Diptesh Kanojia, Naveen Saini and Rudra Murthy

- *Towards Weakly-Supervised Hate Speech Classification Across Datasets*<br>
Yiping Jin, Leo Wanner, Vishakha Kadam and Alexander Shvets

- *Relationality and Offensive Speech: A Research Agenda*<br>
Razvan Amironesei and Mark Diaz

- *Auditing YouTube Content Moderation in Low Resource Language Settings*<br>
Hellina Hailu Nigatu and Inioluwa Raji

- *ExtremeBB: A Database for Large-Scale Research into Online Hate, Harassment, the Manosphere and Extremism*<br>
Anh V. Vu, Lydia Wilson, Yi Ting Chua, Ilia Shumailov and Ross Anderson

- *HOMO-MEX: A Mexican Spanish Annotated Corpus for LGBT+phobia Detection on Twitter*<br>
Juan Vásquez, Scott Andersen, Gemma Bel-enguix, Helena Gómez-adorno and Sergio-luis Ojeda-trueba

- *A Cross-Lingual Study of Homotransphobia on Twitter*<br>
Davide Locatelli, Greta Damo and Debora Nozza

- *[Findings] The State of Profanity Obfuscation in Natural Language Processing Scientific Publications*<br>
Debora Nozza and Dirk Hovy

- *[Findings] It’s not Sexually Suggestive; It’s Educative | Separating Sex Education from Suggestive Content on TikTok videos*<br>
Enfa Rose George and Mihai Surdeanu

- *[Findings] Playing the Part of the Sharp Bully: Generating Adversarial Examples for Implicit Hate Speech Detection*<br>
Nicolas Benjamin Ocampo, Elena Cabrio and Serena Villata

15:00 - 15:45:  Coffee Break

15:45 - 16:15:  **Lauren Klein**: "Historical Data, Real-World Harms"

16:15 - 17:15:  **Panel Discussion** on the special theme with all invited speakers

17:15 - 17:25:  Closing Remarks

From 17:30: **Workshop Drinks**, External Location TBA at the workshop
