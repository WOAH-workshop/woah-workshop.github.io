<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Detailed Schedule | Workshop on Online Abuse and Harms</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Detailed Schedule" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The 7th Workshop on Online Abuse and Harms (WOAH) on July 13th at ACL 2023." />
<meta property="og:description" content="The 7th Workshop on Online Abuse and Harms (WOAH) on July 13th at ACL 2023." />
<link rel="canonical" href="http://localhost:4000/programme.html" />
<meta property="og:url" content="http://localhost:4000/programme.html" />
<meta property="og:site_name" content="Workshop on Online Abuse and Harms" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Detailed Schedule" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"The 7th Workshop on Online Abuse and Harms (WOAH) on July 13th at ACL 2023.","headline":"Detailed Schedule","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/logo_woah.png"}},"url":"http://localhost:4000/programme.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://localhost:4000/">Workshop on Online Abuse and Harms</a></h1>

        
          <img src="/assets/img/logo_woah.png" alt="Logo" />
        

        <p>The 7th Workshop on Online Abuse and Harms (WOAH) on July 13th at ACL 2023.</p>

        

        

        
        
        <li>
        <a href="http://localhost:4000/">Homepage</a>
        </li>
        
          
        
          
            <li>
              <a href="cfp.html">Call For Papers</a>
              <!-- <span> [ cfp.md - Call For Papers - 1 ] </span> -->
            </li>
          
        
          
            <li>
              <a href="organization.html">Organizers</a>
              <!-- <span> [ organization.md - Organizers - 2 ] </span> -->
            </li>
          
        
          
            <li>
              <a href="policies.html">Reporting examples</a>
              <!-- <span> [ policies.md - Reporting examples - 3 ] </span> -->
            </li>
          
        
          
            <li>
              <a href="programme.html">Detailed Schedule</a>
              <!-- <span> [ programme.md - Detailed Schedule - 4 ] </span> -->
            </li>
          
        
      </header>


      </header>
      <section>

      <h2 id="-schedule-"><span style="color:#267CB9"> Schedule </span></h2>

<p>Thursday, July 13th 2023. Toronto time. All sessions are in <strong>PIER 7&amp;8</strong> unless indicated otherwise.</p>

<p>09:00 - 09:15:  Opening Remarks</p>

<p>09:15 - 09:45:  <strong>Dirk Hovy</strong>: “Whose Truth Is It Anyway?”</p>

<p>09:45 - 10:15:  <strong>Vinodkumar Prabhakaran</strong>:</p>

<p>10:15 - 11:45:  <strong>Poster Session</strong> in the <strong>Frontenac Ballroom</strong></p>

<ul>
  <li>
    <p><em>Identity Construction in a Misogynist Incels Forum</em><br />
Michael Yoder, Chloe Perry, David Brown, Kathleen Carley and Meredith Pruden</p>
  </li>
  <li>
    <p><em>DeTexD: A Benchmark Dataset for Delicate Text Detection</em><br />
Artem Chernodub, Serhii Yavnyi, Oleksii Sliusarenko, Jade Razzaghi, Yichen Mo and Knar Hovakimyan</p>
  </li>
  <li>
    <p><em>Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech</em><br />
Flor Miriam Plaza-del-Arco, Debora Nozza and Dirk Hovy</p>
  </li>
  <li>
    <p><em>Benchmarking Offensive and Abusive Language in Dutch Tweets</em><br />
Tommaso Caselli and Hylke Van Der Veen</p>
  </li>
  <li>
    <p><em>Concept-Based Explanations to Test for False Causal Relationships Learned by Abusive Language Classifiers</em><br />
Isar Nejadgholi, Svetlana Kiritchenko, Kathleen C. Fraser and Esma Balkir</p>
  </li>
  <li>
    <p><em>Conversation Derailment Forecasting with Graph Convolutional Networks</em><br />
Enas Altarawneh, Ameeta Agrawal, Michael Jenkin and Manos Papagelis</p>
  </li>
  <li>
    <p><em>Resources for Automated Identification of Online Gender-Based Violence: A Systematic Review</em><br />
Gavin Abercrombie, Aiqi Jiang, Poppy Gerrard-abbott, Ioannis Konstas and Verena Rieser</p>
  </li>
  <li>
    <p><em>Disentangling Disagreements on Offensiveness: A Cross-Cultural Study</em><br />
Aida Mostafazadeh Davani, Mark Diaz, Dylan Baker and Vinodkumar Prabhakaran</p>
  </li>
  <li>
    <p><em>Evaluating the Effectiveness of Natural Language Inference for Hate Speech Detection in Languages with Limited Labeled Data</em><br />
Janis Goldzycher, Moritz Preisig, Chantal Amrhein and Gerold Schneider</p>
  </li>
  <li>
    <p><em>Factoring Hate Speech: A New Annotation Framework to Study Hate Speech in Social Media</em><br />
Gal Ron, Effi Levi, Odelia Oshri and Shaul Shenhav</p>
  </li>
  <li>
    <p><em>Toward Disambiguating the Definitions of Abusive, Offensive, Toxic, and Uncivil Comments</em><br />
Pia Pachinger, Julia Neidhardt, Allan Hanbury and Anna Maria Planitzer</p>
  </li>
  <li>
    <p><em>Harmful Language Datasets: An Assessment of Robustness</em><br />
Katerina Korre, John Pavlopoulos, Jeffrey Sorensen, Léo Laugier, Ion Androutsopoulos, Lucas Dixon and Alberto Barrón-cede ̃no</p>
  </li>
  <li>
    <p><em>Robust Hate Speech Detection in Social Media: A Cross-Dataset Empirical Evaluation</em><br />
Dimosthenis Antypas and Jose Camacho-Collados</p>
  </li>
  <li>
    <p><em>[Findings] Responsibility Perspective Transfer for Italian Femicide News</em><br />
Gosse Minnema, Huiyuan Lai, Benedetta Muscato and Malvina Nissim</p>
  </li>
  <li>
    <p><em>[Findings] Scientific Fact-Checking: A Survey of Resources and Approaches</em><br />
Juraj Vladika and Florian Matthes</p>
  </li>
  <li>
    <p><em>[Findings] A New Task and Dataset on Detecting Attacks on Human Rights Defenders</em><br />
Shihao Ran, Di Lu, Aoife Cahill, Joel Tetreault and Alejandro Jaimes</p>
  </li>
  <li>
    <p><em>[Findings] ClaimDiff: Comparing and Contrasting Claims on Contentious Issues</em><br />
Miyoung Ko, Ingyu Seong, Hwaran Lee, Joonsuk Park, Minsuk Chang and Minjoon Seo</p>
  </li>
  <li>
    <p><em>[Findings] Which Examples Should be Multiply Annotated? Active Learning When Annotators May Disagree</em><br />
Connor T Baumler, Anna Sotnikova and Hal Daumé III</p>
  </li>
  <li>
    <p><em>[Findings] Disagreement Matters: Preserving Label Diversity by Jointly Modeling Item and Annotator Label Distributions with DisCo</em><br />
Tharindu Cyril Weerasooriya, Alexander Ororbia, Raj B Bhensadadia, Ashiqur KhudaBukhsh and Christopher Homan</p>
  </li>
  <li>
    <p><em>[Findings] Debiasing should be Good and Bad</em><br />
Robert A. Morabito, Jad Kabbara and Ali Emami</p>
  </li>
  <li>
    <p><em>[Findings] COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements</em><br />
Xuhui Zhou, Hao Zhu, Akhila Yerukola, Thomas Davidson, Jena D. Hwang, Swabha Swayamdipta and Maarten Sap</p>
  </li>
  <li>
    <p><em>[Findings] Stereotypes and Smut: The (Mis)representation of Non-cisgender Identities by Text-to-Image Models</em><br />
Eddie L. Ungless, Bjorn Ross and Anne Lauscher</p>
  </li>
</ul>

<p>11:45 - 12:15:  <strong>Maarten Sap</strong>: “The Pivotal Role of Social Context in Toxic Language Detection”</p>

<p>12:15 - 13:30:  Lunch Break</p>

<p>13:30 - 14:00:  <strong>Su Lin Blodgett</strong>:</p>

<p>14:00 - 14:30:  <strong>Outstanding Paper Talks</strong></p>

<ul>
  <li>
    <p><em>Cross-Platform and Cross-Domain Abusive Language Detection with Supervised Contrastive Learning</em><br />
Md Tawkat Islam Khondaker, Muhammad Abdul-mageed and Laks Lakshmanan, V.s.</p>
  </li>
  <li>
    <p><em>Aporophobia: An Overlooked Type of Toxic Language Targeting the Poor</em><br />
Svetlana Kiritchenko, Georgina Curto Rex, Isar Nejadgholi and Kathleen C Fraser</p>
  </li>
</ul>

<p>14:30 - 15:00:  <strong>Lightning Talks</strong> for remote attendants</p>

<ul>
  <li>
    <p><em>Towards Safer Communities: Detecting Aggression and Offensive Language in Code-Mixed Tweets to Combat Cyberbullying</em><br />
Nazia Nafis, Diptesh Kanojia, Naveen Saini and Rudra Murthy</p>
  </li>
  <li>
    <p><em>Towards Weakly-Supervised Hate Speech Classification Across Datasets</em><br />
Yiping Jin, Leo Wanner, Vishakha Kadam and Alexander Shvets</p>
  </li>
  <li>
    <p><em>Relationality and Offensive Speech: A Research Agenda</em><br />
Razvan Amironesei and Mark Diaz</p>
  </li>
  <li>
    <p><em>Auditing YouTube Content Moderation in Low Resource Language Settings</em><br />
Hellina Hailu Nigatu and Inioluwa Raji</p>
  </li>
  <li>
    <p><em>ExtremeBB: A Database for Large-Scale Research into Online Hate, Harassment, the Manosphere and Extremism</em><br />
Anh V. Vu, Lydia Wilson, Yi Ting Chua, Ilia Shumailov and Ross Anderson</p>
  </li>
  <li>
    <p><em>HOMO-MEX: A Mexican Spanish Annotated Corpus for LGBT+phobia Detection on Twitter</em><br />
Juan Vásquez, Scott Andersen, Gemma Bel-enguix, Helena Gómez-adorno and Sergio-luis Ojeda-trueba</p>
  </li>
  <li>
    <p><em>A Cross-Lingual Study of Homotransphobia on Twitter</em><br />
Davide Locatelli, Greta Damo and Debora Nozza</p>
  </li>
  <li>
    <p><em>[Findings] The State of Profanity Obfuscation in Natural Language Processing Scientific Publications</em><br />
Debora Nozza and Dirk Hovy</p>
  </li>
  <li>
    <p><em>[Findings] It’s not Sexually Suggestive; It’s Educative | Separating Sex Education from Suggestive Content on TikTok videos</em><br />
Enfa Rose George and Mihai Surdeanu</p>
  </li>
  <li>
    <p><em>[Findings] Playing the Part of the Sharp Bully: Generating Adversarial Examples for Implicit Hate Speech Detection</em><br />
Nicolas Benjamin Ocampo, Elena Cabrio and Serena Villata</p>
  </li>
</ul>

<p>15:00 - 15:30:  <strong>Lauren Klein</strong>: “Historical Data, Real-World Harms”</p>

<p>15:30 - 16:15:  Coffee Break</p>

<p>16:15 - 17:15:  <strong>Panel Discussion</strong> on the special theme with all invited speakers</p>

<p>17:15 - 17:25:  Closing Remarks</p>

<p>From 17:30: <strong>Workshop Drinks</strong>, External Location TBA at the workshop</p>


      </section>
      <footer>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>
